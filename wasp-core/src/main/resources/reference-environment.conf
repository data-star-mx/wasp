# This file includes defaults for environment configuration, mostly external services.

mongo {
  address = "localhost:27017"
  db-name = "wasp"
  timeout = ${default.timeout-services}
}

kafka {
  connections = [
    {
      protocol = ""
      host = "localhost"
      port = 9092
      timeout = ${default.timeout-services}
    }
  ]
  ingest-rate = "1s"
  zookeeper = {
    protocol = ""
    host = "localhost"
    port = 2181
    timeout = ${default.timeout-services}
  }
  broker-id = 0
  partitioner-fqcn = "kafka.producer.DefaultPartitioner"
  default-encoder = "kafka.serializer.DefaultEncoder"
  encoder-fqcn = "kafka.serializer.StringEncoder"
  decoder-fqcn = "kafka.serializer.StringDecoder"
  batch-send-size = 100
}

spark-streaming {
  master = {
    protocol = ""
    host = "local[*]"
    port = 0
  }
  cleaner-ttl = 7200
  streaming-batch-interval-ms = 1000
  checkpoint-dir = "./tmp"
  executor-memory = "2G"
  driver-hostname = "localhost"
  yarn-jar = "./spark-lib/spark-assembly.jar"
}

spark-batch {
  master = {
    protocol = ""
    host = "local[*]"
    port = 0
  }
  cleaner-ttl = 7200
  executor-memory = "2G"
  driver-hostname = "localhost"
  yarn-jar = "./spark-lib/spark-assembly.jar"
}

elastic {
  connections = [
    {
      protocol = ""
      host = "localhost"
      port = 9300
      timeout = ${default.timeout-services},
      metadata : [
        {"connectiontype" : "binary"}
      ]
    },
    {
      protocol = ""
      host = "localhost"
      port = 9200
      timeout = ${default.timeout-services},
      metadata : [
        {"connectiontype" : "rest"}
      ]
    }
  ]
  cluster-name = "elasticsearch"
}

solr {
  connections : [
    {
      protocol : "",
      host : "localhost",
      port : 9983,
      metadata : [
        {"zookeeperRootNode" : ""}
      ]
    }
  ],
  name : "Solr",
  cluster_name : "wasp",
  apiEndPoint : {
    protocol : "http",
    host : "localhost",
    port : 8983,
    metadata : [
      {"zookeeperRootNode" : "/solr"}
    ]
  }
}